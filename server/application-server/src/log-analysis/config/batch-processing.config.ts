export interface BatchProcessingConfig {
  // åŸºç¡€æ‰¹æ¬¡é…ç½®
  baseBatchSize: number;
  maxBatchSize: number;
  minBatchSize: number;
  
  // å¹¶å‘æ§åˆ¶
  maxConcurrency: number;
  parallelBatchThreshold: number;
  
  // å¤§æ•°æ®é‡å¤„ç†
  largeDatasetThreshold: number;
  samplingEnabled: boolean;
  maxSampleSize: number;
  
  // åˆ†å±‚å¤„ç†
  stratifiedProcessing: boolean;
  tierConfigs: TierConfig[];
}

export interface TierConfig {
  name: string;
  priority: number;
  batchSize: number;
  keywords: string[];
  logLevels: string[];
  maxLogs?: number;
}

export const DEFAULT_BATCH_CONFIG: BatchProcessingConfig = {
  // ğŸ”¥ ä¼˜åŒ–æ‰¹æ¬¡å¤§å° - åŸæ¥æ˜¯5ï¼Œç°åœ¨æ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´
  baseBatchSize: 20,      // åŸºç¡€æ‰¹æ¬¡å¤§å°æå‡4å€
  maxBatchSize: 80,       // æœ€å¤§æ‰¹æ¬¡å¤§å°ï¼ˆå¤§æ•°æ®é‡æ—¶ï¼‰
  minBatchSize: 5,        // æœ€å°æ‰¹æ¬¡å¤§å°ï¼ˆå°æ•°æ®é‡æ—¶ï¼‰
  
  // ğŸ”¥ å¹¶å‘æ§åˆ¶ä¼˜åŒ–
  maxConcurrency: 8,      // æœ€å¤§å¹¶å‘æ‰¹æ¬¡æ•°ï¼ˆåŸæ¥æ˜¯1ï¼‰
  parallelBatchThreshold: 50, // è¶…è¿‡50æ¡æ—¥å¿—å¯ç”¨å¹¶è¡Œå¤„ç†
  
  // ğŸ”¥ å¤§æ•°æ®é‡å¤„ç†ç­–ç•¥
  largeDatasetThreshold: 1000, // è¶…è¿‡1000æ¡è®¤ä¸ºæ˜¯å¤§æ•°æ®é‡
  samplingEnabled: true,       // å¯ç”¨æ™ºèƒ½é‡‡æ ·
  maxSampleSize: 500,         // æœ€å¤§é‡‡æ ·æ•°é‡
  
  // ğŸ”¥ åˆ†å±‚å¤„ç†é…ç½®
  stratifiedProcessing: true,
  tierConfigs: [
    {
      name: 'å…³é”®é”™è¯¯å±‚',
      priority: 1,
      batchSize: 80,  // é”™è¯¯æ—¥å¿—æ‰¹æ¬¡å¯ä»¥æ›´å¤§ï¼Œå› ä¸ºæ›´é‡è¦
      keywords: ['error', 'exception', 'fail', 'crash', 'timeout'],
      logLevels: ['FATAL', 'ERROR', 'CRITICAL'],
      maxLogs: 200,   // æœ€å¤šå¤„ç†200æ¡é”™è¯¯æ—¥å¿—
    },
    {
      name: 'è­¦å‘Šå’Œé‡è¦ä¿¡æ¯å±‚',
      priority: 2,
      batchSize: 50,
      keywords: ['warn', 'warning', 'user', 'login', 'payment', 'order'],
      logLevels: ['WARN'],
      maxLogs: 300,
    },
    {
      name: 'ä¸€èˆ¬ä¿¡æ¯å±‚',
      priority: 3,
      batchSize: 30,
      keywords: [],
      logLevels: ['INFO', 'DEBUG', 'TRACE'],
      maxLogs: 500,
    },
  ],
};

// ğŸ”¥ æ ¹æ®æ•°æ®é‡è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°
export function calculateOptimalBatchSize(
  totalLogs: number,
  config: BatchProcessingConfig = DEFAULT_BATCH_CONFIG,
): number {
  if (totalLogs <= 20) {
    return config.minBatchSize;
  } else if (totalLogs <= 100) {
    return config.baseBatchSize;
  } else if (totalLogs <= 500) {
    return Math.floor(config.baseBatchSize * 1.5);
  } else if (totalLogs <= 1000) {
    return Math.floor(config.baseBatchSize * 2);
  } else {
    return config.maxBatchSize;
  }
}

// ğŸ”¥ è®¡ç®—æœ€ä¼˜å¹¶å‘æ•°
export function calculateOptimalConcurrency(
  totalLogs: number,
  batchSize: number,
  config: BatchProcessingConfig = DEFAULT_BATCH_CONFIG,
): number {
  const totalBatches = Math.ceil(totalLogs / batchSize);
  return Math.min(totalBatches, config.maxConcurrency);
}

// ğŸ”¥ è·å–å¤„ç†ç­–ç•¥
export function getProcessingStrategy(
  totalLogs: number,
  config: BatchProcessingConfig = DEFAULT_BATCH_CONFIG,
): 'standard' | 'parallel' | 'stratified' | 'sampled' {
  if (totalLogs >= config.largeDatasetThreshold) {
    return 'stratified';
  } else if (totalLogs >= config.parallelBatchThreshold) {
    return 'parallel';
  } else {
    return 'standard';
  }
}

// ğŸ”¥ è·å–æ‰¹æ¬¡å¤„ç†ç»Ÿè®¡ä¿¡æ¯
export function getBatchProcessingStats(
  totalLogs: number,
  config: BatchProcessingConfig = DEFAULT_BATCH_CONFIG,
): {
  strategy: string;
  optimalBatchSize: number;
  estimatedBatches: number;
  optimalConcurrency: number;
  estimatedLLMCalls: number;
  estimatedProcessingTime: string;
  willUseSampling: boolean;
} {
  const strategy = getProcessingStrategy(totalLogs, config);
  const optimalBatchSize = calculateOptimalBatchSize(totalLogs, config);
  const estimatedBatches = Math.ceil(totalLogs / optimalBatchSize);
  const optimalConcurrency = calculateOptimalConcurrency(totalLogs, optimalBatchSize, config);
  const willUseSampling = strategy === 'stratified' && config.samplingEnabled;
  
  // ä¼°ç®—å¤„ç†æ—¶é—´ï¼ˆå‡è®¾æ¯ä¸ªLLMè°ƒç”¨å¹³å‡2ç§’ï¼‰
  const estimatedSeconds = Math.ceil(estimatedBatches / optimalConcurrency * 2);
  
  return {
    strategy,
    optimalBatchSize,
    estimatedBatches,
    optimalConcurrency,
    estimatedLLMCalls: estimatedBatches,
    estimatedProcessingTime: `${estimatedSeconds}ç§’`,
    willUseSampling,
  };
} 