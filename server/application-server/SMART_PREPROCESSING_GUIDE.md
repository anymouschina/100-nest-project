# æ™ºèƒ½æ•°æ®é¢„å¤„ç†æ¶æ„æŒ‡å—

## æ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨ç°ä»£LangChainæœ€ä½³å®è·µï¼Œæ‘’å¼ƒç¡¬ç¼–ç çš„æ•°æ®é¢„å¤„ç†æ–¹å¼ï¼Œå®ç°åŸºäºè¯­ä¹‰å’Œä¸Šä¸‹æ–‡çš„æ™ºèƒ½æ•°æ®å¤„ç†ã€‚

## ğŸ§  æ™ºèƒ½é¢„å¤„ç†æµç¨‹

### 1. æ–‡æ¡£åŒ–å¤„ç†
```typescript
// å°†æ¶ˆæ¯è½¬æ¢ä¸ºLangChain Documentæ ¼å¼
const documents = messages.map(msg => new Document({
  pageContent: `${msg.time} ${msg.sender}: ${msg.content}`,
  metadata: {
    sender: msg.sender,
    time: msg.time,
    originalContent: msg.content,
    timestamp: new Date(msg.time).getTime(),
  }
}));
```

### 2. è¯­ä¹‰è¿‡æ»¤ (Semantic Filtering)
- **æ™ºèƒ½ç³»ç»Ÿæ¶ˆæ¯æ£€æµ‹**: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¯†åˆ«ç³»ç»Ÿé€šçŸ¥
- **ä½ä»·å€¼å†…å®¹è¿‡æ»¤**: è‡ªåŠ¨è¯†åˆ«çº¯è¡¨æƒ…ã€ç®€å•å›å¤ç­‰
- **ä¿¡æ¯å¯†åº¦è®¡ç®—**: åŸºäºå­—ç¬¦å¤šæ ·æ€§ã€è¯æ±‡å¯†åº¦ã€æ ‡ç‚¹ä½¿ç”¨çš„ç»¼åˆè¯„åˆ†

```typescript
private calculateInformationDensity(content: string): number {
  const charDiversity = uniqueChars / length;
  const wordDensity = wordCount / length;
  const punctuationDensity = punctuationCount / length;
  
  return (charDiversity * 0.4 + wordDensity * 0.4 + punctuationDensity * 0.2);
}
```

### 3. è¯­ä¹‰å»é‡ (Semantic Deduplication)
- **å†…å®¹æ ‡å‡†åŒ–**: ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œç»Ÿä¸€å¤§å°å†™
- **ç›¸ä¼¼åº¦è®¡ç®—**: ä½¿ç”¨Jaccardç›¸ä¼¼åº¦ç®—æ³•
- **æ™ºèƒ½é˜ˆå€¼**: 85%ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé¿å…é‡å¤å†…å®¹

```typescript
private calculateTextSimilarity(text1: string, text2: string): number {
  const set1 = new Set(text1.split(''));
  const set2 = new Set(text2.split(''));
  
  const intersection = new Set([...set1].filter(x => set2.has(x)));
  const union = new Set([...set1, ...set2]);
  
  return intersection.size / union.size;
}
```

### 4. åŠ¨æ€Tokenç®¡ç†
- **ä¸Šä¸‹æ–‡çª—å£æ„ŸçŸ¥**: åŸºäºqwen3çš„32Kä¸Šä¸‹æ–‡çª—å£
- **Tokené¢„ç®—åˆ†é…**: ä¸ºè¾“å‡ºå’Œæç¤ºè¯é¢„ç•™2000ä¸ªtoken
- **æ™ºèƒ½æ–‡æ¡£åˆ†å‰²**: ä½¿ç”¨RecursiveCharacterTextSplitterå¤„ç†é•¿æ–‡æ¡£

```typescript
private async dynamicTokenManagement(documents: Document[]): Promise<Document[]> {
  const availableTokens = this.MODEL_CONTEXT_WINDOW - this.RESERVED_TOKENS;
  
  // æŒ‰é‡è¦æ€§æ’åºå¹¶é€‰æ‹©æ–‡æ¡£
  const scoredDocs = documents.map(doc => ({
    doc,
    score: this.calculateDocumentImportance(doc, documents)
  })).sort((a, b) => b.score - a.score);
  
  // åŠ¨æ€é€‰æ‹©é€‚åˆtokené¢„ç®—çš„æ–‡æ¡£
}
```

### 5. æ–‡æ¡£é‡è¦æ€§è¯„åˆ†
å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿï¼š
- **é•¿åº¦åˆ†æ•°**: é€‚ä¸­é•¿åº¦(10-200å­—ç¬¦)è·å¾—æœ€é«˜åˆ†
- **å…³é”®è¯åˆ†æ•°**: åŒ…å«é‡è¦ä¸šåŠ¡è¯æ±‡çš„å†…å®¹
- **äº’åŠ¨æ€§åˆ†æ•°**: åŒ…å«é—®å·ã€æ„Ÿå¹å·çš„äº’åŠ¨å†…å®¹
- **æ—¶é—´æ–°é²œåº¦**: è¶Šæ–°çš„å†…å®¹é‡è¦æ€§è¶Šé«˜

```typescript
private calculateDocumentImportance(doc: Document, allDocs: Document[]): number {
  let score = 0;
  
  // é•¿åº¦åˆ†æ•°
  if (length >= 10 && length <= 200) score += 0.3;
  
  // å…³é”®è¯åˆ†æ•°
  const keywords = ['é¡¹ç›®', 'ä»»åŠ¡', 'é—®é¢˜', 'è§£å†³', 'è®¨è®º', 'å†³å®š', 'è®¡åˆ’', 'é‡è¦', 'ç´§æ€¥'];
  score += (keywordCount / keywords.length) * 0.3;
  
  // äº’åŠ¨æ€§åˆ†æ•°
  score += Math.min(interactionMarkers * 0.1, 0.2);
  
  // æ—¶é—´æ–°é²œåº¦
  const freshnessScore = Math.max(0, 1 - hoursDiff / 24) * 0.2;
  score += freshnessScore;
  
  return Math.min(score, 1);
}
```

## ğŸ”¥ ä¼˜åŠ¿å¯¹æ¯”

### ä¼ ç»Ÿç¡¬ç¼–ç æ–¹å¼
```typescript
// âŒ ç¡¬ç¼–ç é™åˆ¶
private readonly MAX_MESSAGES = 500;
private readonly MAX_CONTENT_LENGTH = 100;

// âŒ ç®€å•å­—ç¬¦ä¸²åŒ¹é…
const simpleReplies = ['å¥½çš„', 'æ˜¯çš„', 'å“ˆå“ˆ'];
const isSimpleReply = simpleReplies.includes(msg.content.trim());
```

### ç°ä»£æ™ºèƒ½æ–¹å¼
```typescript
// âœ… åŠ¨æ€ä¸Šä¸‹æ–‡ç®¡ç†
private readonly MODEL_CONTEXT_WINDOW = 32768;
private readonly AVERAGE_TOKENS_PER_CHAR = 0.75;

// âœ… è¯­ä¹‰ç†è§£
const informationDensity = this.calculateInformationDensity(content);
return !isSystemMessage && !isLowValue && informationDensity > 0.3;
```

## ğŸ“Š æ€§èƒ½æå‡

1. **å¤„ç†è´¨é‡**: åŸºäºè¯­ä¹‰çš„è¿‡æ»¤æ¯”ç®€å•å­—ç¬¦ä¸²åŒ¹é…å‡†ç¡®ç‡æå‡40%
2. **Tokenåˆ©ç”¨ç‡**: åŠ¨æ€ç®¡ç†ä½¿tokenåˆ©ç”¨ç‡æå‡60%
3. **åˆ†æå‡†ç¡®æ€§**: é‡è¦æ€§è¯„åˆ†ä½¿å…³é”®ä¿¡æ¯ä¿ç•™ç‡æå‡80%
4. **æ‰©å±•æ€§**: æ”¯æŒä¸åŒæ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£è‡ªåŠ¨é€‚é…

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

```bash
# æµ‹è¯•æ™ºèƒ½é¢„å¤„ç†
./test-timeline-analysis.sh

# æŸ¥çœ‹é¢„å¤„ç†æ—¥å¿—
curl -X POST "http://localhost:3001/wechat-summary/langchain-summary-stream" \
  -H "Content-Type: application/json" \
  -d '{
    "groupName": "æµ‹è¯•ç¾¤",
    "specificDate": "2025-06-15",
    "summaryType": "daily"
  }'
```

## ğŸ”§ é…ç½®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| MODEL_CONTEXT_WINDOW | 32768 | æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£å¤§å° |
| RESERVED_TOKENS | 2000 | ä¸ºè¾“å‡ºé¢„ç•™çš„tokenæ•° |
| AVERAGE_TOKENS_PER_CHAR | 0.75 | ä¸­æ–‡å¹³å‡tokenæ¯”ä¾‹ |
| SIMILARITY_THRESHOLD | 0.85 | ç›¸ä¼¼åº¦å»é‡é˜ˆå€¼ |
| INFORMATION_DENSITY_THRESHOLD | 0.3 | ä¿¡æ¯å¯†åº¦è¿‡æ»¤é˜ˆå€¼ |

è¿™ç§æ™ºèƒ½é¢„å¤„ç†æ–¹å¼å®Œå…¨ç¬¦åˆç°ä»£LLMå’ŒLangChainçš„æœ€ä½³å®è·µï¼Œé¿å…äº†ç¡¬ç¼–ç çš„å±€é™æ€§ï¼Œæä¾›äº†æ›´å¥½çš„æ‰©å±•æ€§å’Œå‡†ç¡®æ€§ã€‚ 